## 机器学习开发流程

获取数据

数据处理

特征工程

模型选择

模型评估

## 特征工程

### 数据集

sklearn数据集:load\_\*小数据集;fetch\_\*大数据集

### 特征抽取(字符串转向量)

sklearn.feature_extraction

1.字典特征提取 --one-hot编码

DictVectorizer(sparse=True)

sparse=True返回sparse(稀疏)矩阵,节省内存,提高加载效率

应用场景:数据集中类别特征较多或数据本身就是字典类型

2.文本特征提取(默认返回sparse矩阵,用toarray()可转换为二维矩阵)

方法一:CountVectorizer 统计每个样本特征词出现个数,stop_words停用词表

方法二:TfidfVectorizer 词频-逆文档频率

![](./image1.png){width="2.451514654418198in"
height="0.6250317147856518in"}

例:两个词"经济"，"非常"

1000篇文章-语料库

100篇文章－\"非常\"

10篇文章－"经济"

两篇文章

文章A（100词）：10次"经济"

tf: 10/100=0.1

idf: lg 1000/10=2

TF-IDF：0.2

文章B（100词）：10次"非常"

tf: 10/100=0.1

idf: lg 1000/100=1

TF-IDF：0.1

### 特征预处理

无量纲化

1.归一化:将不同规格的数据转换成相同规格

![](./image2.png){width="4.4030041557305335in"
height="0.7917071303587052in"}

MinMaxScaler(feature_range=(0,1))

受异常值影响大

2.[标准化]{.mark}:对原始数据变换到均值为0,标准差为1

[StandardScaler()]{.mark}

![](./image3.png){width="2.715417760279965in"
height="1.4097944006999126in"}

### 特征降维

特征选择(降低特征个数,得到特征与特征之间不相关的主变量)

Filter过滤式:特征与特征和目标值之间的关联

方差选择法:低方差特征过滤

相关系数法:皮尔逊相关系数

![](./image4.png){width="3.3890627734033245in"
height="0.6805905511811023in"}

[Embeded嵌入式]{.mark}:算法自选择特征,特征与目标值之间的关联

决策树

正则化

深度学习

### 主成分分析(PCA):降维时尽可能减少数据丢失

transfer = PCA(n_components)

n_components取整数则减少到 对应数量特征,取小数则保留百分之数量的信息

去冗余特征如0等
